{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, BatchNormalization, Dropout, Embedding, Flatten, Concatenate, Input\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "from time_series import create_features, ewma, player_moving_average, team_moving_average, \n",
    "from ml_pipeline import encode_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "df = pd.read_csv('player_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_features(df)\n",
    "df = player_moving_average(df)\n",
    "merged_df = team_moving_average(df)\n",
    "df = merged_df.dropna()\n",
    "df = encode_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'bps_ewma',                \n",
    "    'total_points_ewma',\n",
    "    'threat_ewma',\n",
    "    'creativity_ewma',           \n",
    "    'yellow_cards_ewma',\n",
    "    'saves_ewma',                    \n",
    "    'goals_scored_ewma',\n",
    "    'assists_ewma',\n",
    "    'clean_sheets_ewma',        \n",
    "    'transfers_in_rank',\n",
    "    'transfers_out_rank',\n",
    "    'bonus_ewma',                 \n",
    "     'value',\n",
    "     'scored_opp_ewma',   \n",
    "     'conceded_opp_ewma',  \n",
    "     'scored_team_ewma',   \n",
    "     'conceded_team_ewma',\n",
    "     'was_home',\n",
    "     'position_GK',\n",
    "     'position_DEF', \n",
    "     'position_MID',\n",
    "     'position_FWD',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"total_points\"\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_date = '2022-07-01'\n",
    "test_date = '2024-07-20'\n",
    "\n",
    "train_data = df[df[\"date\"] < train_date]\n",
    "val_data = df[(df[\"date\"] >= train_date) & (df[\"date\"] <= test_date)]\n",
    "test_data = df[df[\"date\"] > test_date]\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "X_val = val_data[features]\n",
    "y_val = val_data[target]\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target]\n",
    "\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))\n",
    "print('train', len(train_data)/(len(test_data)+len(train_data)+len(val_data))*100)\n",
    "print('test', len(test_data)/(len(test_data)+len(train_data)+len(val_data))*100)\n",
    "print('val',len(val_data)/(len(train_data)+len(val_data)+len(test_data))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  # Monitor validation loss\n",
    "                               patience=10,  # Number of epochs with no improvement before stopping\n",
    "                               restore_best_weights=True)  # Restore the model's best weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldrop = Sequential()\n",
    "modeldrop.add(Dense(units=X_train_scaled.shape[1], activation='relu'))\n",
    "#modeldrop.add(Dense(units=64, activation='relu'))\n",
    "modeldrop.add(Dense(units=32, activation='relu'))\n",
    "modeldrop.add(Dense(units=16, activation='relu'))\n",
    "modeldrop.add(Dense(units=1, activation='relu'))\n",
    "modeldrop.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "dropout = modeldrop.fit(X_train_scaled, y_train,epochs=30, batch_size=32,validation_data=(X_val_scaled, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqxKWoe91NRQ"
   },
   "source": [
    "# **Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = modeldrop.predict(X_test_scaled)\n",
    "test_data['predicted_points'] = y_pred\n",
    "test_data['points_per_mil'] = test_data[\"predicted_points\"] / test_data[\"value\"]\n",
    "\n",
    "# Select relevant columns and round predicted points\n",
    "predicted_df = test_data[[\n",
    "    \"name\", \"season\", \"round\", \"predicted_points\", \"total_points\", \n",
    "    \"team\", \"position\", \"value\", \"opp_team_name\"\n",
    "]]\n",
    "predicted_df['predicted_points'] = predicted_df['predicted_points'].round(2)\n",
    "\n",
    "# Group predictions by season and round\n",
    "grouped_predictions = predicted_df.groupby([\"season\", \"round\"]).apply(lambda x: x.nlargest(10, \"predicted_points\"))\n",
    "grouped_actual = predicted_df.groupby([\"season\", \"round\"]).apply(lambda x: x.nlargest(5, \"total_points\"))\n",
    "grouped_all = predicted_df.groupby([\"season\", \"round\"]).apply(lambda x: x.sort_values(\"predicted_points\", ascending=False))\n",
    "\n",
    "# Aggregate total predicted and actual points\n",
    "total_predicted_points = grouped_all.groupby('name')['predicted_points'].sum()\n",
    "total_actual_points = grouped_all.groupby('name')['total_points'].sum()\n",
    "\n",
    "# Create a DataFrame with season totals\n",
    "season_totals = pd.DataFrame({\n",
    "    'player': total_predicted_points.index,\n",
    "    'total predicted points': total_predicted_points,\n",
    "    'total points': total_actual_points\n",
    "})\n",
    "\n",
    "# Sort players by total points\n",
    "sorted_totals = season_totals.sort_values('total points', ascending=False)\n",
    "\n",
    "# Plot actual vs predicted points\n",
    "sorted_totals.plot(\n",
    "    kind='scatter', x='total predicted points', y='total points', \n",
    "    title=\"Points vs Predicted Points\", xlim=(0, 300), ylim=(0, 300)\n",
    ")\n",
    "plt.plot([0, 300], [0, 300], color='red', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Define required players per position\n",
    "num_players_needed = {\"GK\": 1, \"DEF\": 3, \"MID\": 5, \"FWD\": 2}\n",
    "dream_team = pd.DataFrame(columns=predicted_df.columns)\n",
    "\n",
    "# Select top players for each season, round, and position\n",
    "for season, round in predicted_df[['season', 'round']].drop_duplicates().values:\n",
    "    for position, num_players in num_players_needed.items():\n",
    "        top_players = predicted_df[\n",
    "            (predicted_df['season'] == season) & \n",
    "            (predicted_df['round'] == round) & \n",
    "            (predicted_df['position'] == position)\n",
    "        ].head(num_players)\n",
    "        dream_team = pd.concat([dream_team, top_players])\n",
    "\n",
    "# Calculate cumulative dream team points\n",
    "dream_team_sum = dream_team.groupby(['season', 'round']).agg({\n",
    "    'predicted_points': 'sum',\n",
    "    'total_points': 'sum'\n",
    "}).reset_index()\n",
    "dream_team_sum['total_points'] = pd.to_numeric(dream_team_sum['total_points'], errors='coerce')\n",
    "dream_team_sum['total_points_cumsum'] = dream_team_sum.groupby('season')['total_points'].cumsum()\n",
    "\n",
    "# Calculate highest predicted points per round\n",
    "dream_team['max_points'] = dream_team.groupby(['season', 'round'])['predicted_points'].transform('max')\n",
    "\n",
    "# Double the total points for the highest predicted player in each round\n",
    "dream_team['doubled_highest_points'] = dream_team.apply(\n",
    "    lambda row: row['total_points'] * 2 if row['predicted_points'] == row['max_points'] else row['total_points'], \n",
    "    axis=1\n",
    ")\n",
    "dream_team.drop('max_points', axis=1, inplace=True)\n",
    "\n",
    "# Print summary statistics\n",
    "print('Dream team total sum:', dream_team['total_points'].sum())\n",
    "print('Dream team total sum with captain points doubled:', dream_team['doubled_highest_points'].sum())\n",
    "\n",
    "# Filter for the 2024-25 season\n",
    "df_2024_25 = dream_team[dream_team['season'] == '2024-25']\n",
    "print('Dream team 2024-25 sum:', df_2024_25['total_points'].sum())\n",
    "print('Dream team 2024-25 sum with captain points doubled:', df_2024_25['doubled_highest_points'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all[grouped_all['name']== 'Alisson Ramses Becker'][['predicted_points', 'total_points']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "grouped_predictions.iloc[-20:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldrop.save('model.h5')\n",
    "joblib.dump(scaler, 'scaler.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
